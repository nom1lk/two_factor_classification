library(caret)
library(tm)
library(SnowballC)
library(arm)
library(doParallel)
library(dplyr)
Sys.setenv(TZ="Australia/Sydney")
tryCatch(setwd("C:/Users/Administrator"), error=function(e) {})
all_cats <- read.csv("C:/Users/Steve Condylios/Documents/scraping_bunnings/all_cats_clean_for_ML_20180105.csv", header=TRUE)
all_cats <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/all_cats_clean_for_ML_20180105.csv", header=TRUE)
# Inspect
rel <- all_cats[all_cats$one_if_rel == 1,]
irrel <- all_cats[all_cats$one_if_rel == 0,]
# get a sample of 5000 from each of relevant and irrelevant
set.seed(1000)
rel_5k <- rel[sample(nrow(rel), 5000), ]
set.seed(1000)
irrel_5k <- irrel[sample(nrow(irrel), 5000), ]
all_cats.training <- rbind(rel_5k, irrel_5k)
# Training data.
data <- all_cats.training$product
corpus <- VCorpus(VectorSource(data))
# Create a document term matrix.
tdm <- DocumentTermMatrix(corpus, list(removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))
# Convert to a data.frame for training and assign a classification (factor) to each document.
train <- as.matrix(tdm)
# These objects can go now
# rm(data, corpus, tdm); gc()
train <- cbind(train, all_cats.training$one_if_rel)
colnames(train)[ncol(train)] <- "one_if_rel"
train <- as.data.frame(train)
train$one_if_rel <- as.factor(train$one_if_rel)
# Idea from web
names(train) <- make.names(names(train)); gc()
names(train)
dim(train)
grepl("chrome", colnames(train))
colnames(train)[grepl("chrome", colnames(train))]
train1 <- train[,-"chrom"]
train1 <- train[,!c("chrome")]
train1 <- train[,-c("chrome")]
train1 <- train[,!("chrome")]
train1 <- train[,!c("chrome")]
# Remove "chrome" as it results in a LOT of false positives
train$chrome <- NULL
cl <- makeCluster(detectCores()-1)
registerDoParallel(cl)
fit <- train(one_if_rel ~ ., data = train, method = 'LogitBoost'
,model = FALSE # Added to try to reduce the function holding raw data and models. See: https://stackoverflow.com/questions/6543999/why-is-caret-train-taking-up-so-much-memory
)
stopCluster(cl)
# Check accuracy on training. # Note: when predicting for test or other new datasets, only keep the columns that are contained in the fit (i.e. fit[[11]][3][[1]])
# relevant_cols <- fit[[11]][3][[1]]
a <- predict(fit, newdata = train)
gc()
# Check accuracy - 87% accurate:
b <- cbind(train, a)
b[b$one_if_rel == b$a, ] %>% nrow(.) / nrow(b)
data_63312 <- all_cats$product
corpus_63312 <- VCorpus(VectorSource(data_63312))
# for test or subsequent sets use:
# note: had many unpleasant errors here along the lines of: Error in simple_triplet_matrix(i, j, v, nrow = length(terms), ncol = length(corpus), : 'i, j' invalid
# to fix, I install.packages("") all the relevant packages
tdm_subsequent_data <- DocumentTermMatrix(corpus_63312, control = list(dictionary = Terms(tdm), removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))
train <- as.matrix(tdm_subsequent_data)
train <- as.data.frame(train)
names(train) <- make.names(names(train)); gc()
a <- predict(fit, newdata = train)
all_cats <- cbind(all_cats, a)
all_cats[all_cats$one_if_rel == all_cats$a, ] %>% nrow(.) / nrow(all_cats)
# how many new possibly relevant products? 800
all_cats[all_cats$one_if_rel == 0 & all_cats$a == 1,] %>% nrow()
0.4 * 63000
0.004 * 63000
all_cats <- all_cats[, c(1,2,7,8)]
all_cats$a <- as.numeric(as.character(all_cats$a))
colnames(all_cats)[4] <- "ML_one_if_rel"
getwd()
setwd("~/Feature Engineering")
setwd("/Feature Engineering")
setwd("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification//Feature Engineering")
getwd()
dir()
# setwd("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification//Feature Engineering")
saveRDS(all_cats, "bunnings_pre_labelled.rds")
saveRDS(tdm, "tdm.rds") # original tdm necessary to use in Terms(tdm) in creating any new tdm - may be a more efficient way of storing this info (for this ML model it's around half a gig)
saveRDS(fit, "bunnings_text_classification_fit.rds")
dim(tdm)
tdm[1:5, 1:5]
str(tdm)
tdm[["dimnames"]]
all_cats[all_cats$one_if_rel == 1, ] %>% nrow()
all_cats[all_cats$ML_one_if_rel == 1, ] %>% nrow()
all_cats_fresh <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/bunnings_20180218.csv", header=TRUE, stringsAsFactors = FALSE)
data_fresh <- all_cats$product
corpus_fresh <- VCorpus(VectorSource(data_fresh))
# for test or subsequent sets use:
# note: had many unpleasant errors here along the lines of: Error in simple_triplet_matrix(i, j, v, nrow = length(terms), ncol = length(corpus), : 'i, j' invalid
# to fix, I install.packages("") all the relevant packages
tdm_fresh <- DocumentTermMatrix(corpus_fresh, control = list(dictionary = Terms(tdm), removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))
train <- as.matrix(tdm_fresh)
train <- as.data.frame(train)
names(train) <- make.names(names(train)); gc()
a <- predict(fit, newdata = train)
all_cats_fresh <- cbind(all_cats_fresh, a)
dim(train)
train <- as.matrix(tdm_fresh)
train <- as.data.frame(train)
names(train) <- make.names(names(train)); gc()
a <- predict(fit, newdata = train)
gc()
a <- predict(fit, newdata = train)
rm(list=ls())
gc()
setwd("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/")
setwd("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering")
fit <- readRDS("bunnings_text_classification_fit.rds")
tdm <- readRDS("tdm.rds")
all_cats_fresh <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/bunnings_20180218.csv", header=TRUE, stringsAsFactors = FALSE)
data_fresh <- all_cats$product
data_fresh <- all_cats_fresh$product
corpus_fresh <- VCorpus(VectorSource(data_fresh))
# for test or subsequent sets use:
# note: had many unpleasant errors here along the lines of: Error in simple_triplet_matrix(i, j, v, nrow = length(terms), ncol = length(corpus), : 'i, j' invalid
# to fix, I install.packages("") all the relevant packages
tdm_fresh <- DocumentTermMatrix(corpus_fresh, control = list(dictionary = Terms(tdm), removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))
train <- as.matrix(tdm_fresh)
train <- as.data.frame(train)
names(train) <- make.names(names(train)); gc()
a <- predict(fit, newdata = train)
all_cats_fresh <- cbind(all_cats_fresh, a)
all_cats_fresh[all_cats_fresh$one_if_rel == all_cats_fresh$a, ] %>% nrow(.) / nrow(all_cats_fresh)
# how many new possibly relevant products? 800. After feature-engineering out "chrome" ML identifies 426 relevant products outside of obvious categories
# This is far fewer than the ~800 it initially identified, but it is now far more accurate
all_cats_fresh[all_cats_fresh$one_if_rel == 0 & all_cats_fresh$a == 1,] %>% nrow()
head(all_cats_fresh)
colnames(all_cats_fresh)
all_cats_fresh[all_cats_fresh$one_if_rel == 1, ] %>% nrow
all_cats_fresh <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/bunnings_20180218.csv", header=TRUE, stringsAsFactors = FALSE)
head(all_cats_fresh)
all_cats_fresh$one_if_rel <- NULL
all_cats_fresh$ML_one_if_rel <- NULL
a <- predict(fit, newdata = train)
# Check accuracy - 95% accurate (small improvement to 95.33% when removing "chrome"):
all_cats_fresh <- cbind(all_cats_fresh, a)
all_cats_fresh[all_cats_fresh$one_if_rel == all_cats_fresh$a, ] %>% nrow(.) / nrow(all_cats_fresh)
# how many new possibly relevant products? 800. After feature-engineering out "chrome" ML identifies 426 relevant products outside of obvious categories
# This is far fewer than the ~800 it initially identified, but it is now far more accurate
all_cats_fresh[all_cats_fresh$one_if_rel == 0 & all_cats_fresh$a == 1,] %>% nrow()
all_cats_fresh <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/bunnings_20180218.csv", header=TRUE, stringsAsFactors = FALSE)
all_cats_fresh$ML_one_if_rel <- NULL
a <- predict(fit, newdata = train)
# Check accuracy - 95% accurate (small improvement to 95.33% when removing "chrome"):
all_cats_fresh <- cbind(all_cats_fresh, a)
all_cats_fresh[all_cats_fresh$one_if_rel == all_cats_fresh$a, ] %>% nrow(.) / nrow(all_cats_fresh)
# how many new possibly relevant products? 800. After feature-engineering out "chrome" ML identifies 426 relevant products outside of obvious categories
# This is far fewer than the ~800 it initially identified, but it is now far more accurate
all_cats_fresh[all_cats_fresh$one_if_rel == 0 & all_cats_fresh$a == 1,] %>% nrow()
# how many new possibly relevant products? 800. After feature-engineering out "chrome" ML identifies 426 relevant products outside of obvious categories
# This is far fewer than the ~800 it initially identified, but it is now far more accurate
all_cats_fresh[all_cats_fresh$one_if_rel == 0 & all_cats_fresh$a == 1,] %>% nrow()
# Taking in bunnings_date.csv directly from scrape
all_cats_fresh <- read.csv("C:/Users/Steve Condylios/Documents/Amazon/Training ML model for bunnings product two factor classification/Feature Engineering/Fresh labels for matching app/bunnings_20180218.csv", header=TRUE, stringsAsFactors = FALSE)
all_cats_fresh$ML_one_if_rel <- NULL
f_label <- function(category) { ifelse(category == "Garden - Watering Accessories" || category == "Outdoor Living - Swimming Pools Spa"
|| category == "Kitchen - Kitchen Taps Sinks" || category == "Kitchen - Splashbacks"
|| category == "Bathroom Plumbing - Bathroom" || category == "Bathroom Plumbing - Plumbing",
1,0) }
all_cats$one_if_rel <- mapply(f_label, all_cats$category)
f_label <- function(category) { ifelse(category == "Garden - Watering Accessories" || category == "Outdoor Living - Swimming Pools Spa"
|| category == "Kitchen - Kitchen Taps Sinks" || category == "Kitchen - Splashbacks"
|| category == "Bathroom Plumbing - Bathroom" || category == "Bathroom Plumbing - Plumbing",
1,0) }
all_cats_fresh$one_if_rel <- mapply(f_label, all_cats_fresh$category)
all_cats <- all_cats[!duplicated(all_cats[,c(1,2)]), ]
all_cats_fresh <- all_cats_fresh[!duplicated(all_cats_fresh[,c(1,2)]), ]
data_fresh <- all_cats_fresh$product
corpus_fresh <- VCorpus(VectorSource(data_fresh))
# for test or subsequent sets use:
# note: had many unpleasant errors here along the lines of: Error in simple_triplet_matrix(i, j, v, nrow = length(terms), ncol = length(corpus), : 'i, j' invalid
# to fix, I install.packages("") all the relevant packages
tdm_fresh <- DocumentTermMatrix(corpus_fresh, control = list(dictionary = Terms(tdm), removePunctuation = TRUE, stopwords = TRUE, stemming = TRUE, removeNumbers = TRUE))
train <- as.matrix(tdm_fresh)
train <- as.data.frame(train)
names(train) <- make.names(names(train)); gc()
a <- predict(fit, newdata = train)
all_cats_fresh <- cbind(all_cats_fresh, a)
all_cats_fresh[all_cats_fresh$one_if_rel == all_cats_fresh$a, ] %>% nrow(.) / nrow(all_cats_fresh)
# how many new possibly relevant products? 800. After feature-engineering out "chrome" ML identifies 426 relevant products outside of obvious categories
# This is far fewer than the ~800 it initially identified, but it is now far more accurate
all_cats_fresh[all_cats_fresh$one_if_rel == 0 & all_cats_fresh$a == 1,] %>% nrow()
rm(list=ls())
gc()
